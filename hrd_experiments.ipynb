{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1WhlRE9VMTTo",
        "5CdRCfOmMWSG",
        "OywRfxxeWNT1",
        "i_KD33-GwJ9T",
        "VyCKfHFG-UiF",
        "rVc-JYpR-agK"
      ],
      "mount_file_id": "1gB6idZ6vnQ_52FH7caEId1lfSyqac2jS",
      "authorship_tag": "ABX9TyMLSuKdD9qnhM3fg6aizsgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay8297/Harvard-Rare-Disease-Hackathon/blob/main/hrd_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ],
      "metadata": {
        "id": "1WhlRE9VMTTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pronto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFKKxow-GJVz",
        "outputId": "005cd84a-0f11-40b4-b924-561a1c0b6da8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pronto\n",
            "  Downloading pronto-2.6.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: chardet~=5.0 in /usr/local/lib/python3.11/dist-packages (from pronto) (5.2.0)\n",
            "Collecting fastobo~=0.13.0 (from pronto)\n",
            "  Downloading fastobo-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: networkx<4.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from pronto) (3.4.2)\n",
            "Requirement already satisfied: python-dateutil~=2.8 in /usr/local/lib/python3.11/dist-packages (from pronto) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil~=2.8->pronto) (1.17.0)\n",
            "Downloading pronto-2.6.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastobo-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastobo, pronto\n",
            "Successfully installed fastobo-0.13.0 pronto-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bqbL2A-DGAsx"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pronto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pheno_ontology = pronto.Ontology('./hpo.obo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1F9MN1lGEu2",
        "outputId": "cdf5c64d-42cb-4ad4-ab8d-a0a68c2bfe45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-445b7bd13fd2>:1: UnicodeWarning: unsound encoding, assuming ISO-8859-1 (73% confidence)\n",
            "  pheno_ontology = pronto.Ontology('./hpo.obo')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hpo = pheno_ontology\n",
        "pheno = hpo.get_term('HP:0000059')"
      ],
      "metadata": {
        "id": "8wEnVgC9Gfj9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ancestors_up_to_root(ontology, start_term, stop_term='HP:0000118'):\n",
        "    \"\"\"\n",
        "    :param ontology: pronto Ontology object (computed in function \"load_ontology\")\n",
        "    :param start_term: specific HPO term (e.g., 'HP:0000164')\n",
        "    :param stop_term: root term, known to be 'HP:0000118' (phenotypic abnormality)\n",
        "    :return: set of all parent terms up to the root term\n",
        "    \"\"\"\n",
        "\n",
        "    ancestors = set()\n",
        "    current_term = ontology[start_term]\n",
        "\n",
        "    for parent in current_term.superclasses():\n",
        "        if parent.id == current_term.id: # first item is always the term itself\n",
        "            continue\n",
        "        if parent.id == stop_term:\n",
        "            break\n",
        "        ancestors.add(parent.id)\n",
        "\n",
        "    return ancestors"
      ],
      "metadata": {
        "id": "in_kHmdrIBe5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_disease_annotations(hpo_disease_annotations):\n",
        "    \"\"\"\n",
        "    :param hpo_disease_annotations: full path to the tab-delimited \"phenotype.hpoa\" file downloaded from HPO\n",
        "    :return: dictionary from disease ID -> set of corresponding HPO terms AND dictionary from disease ID -> name\n",
        "    \"\"\"\n",
        "\n",
        "    disease_to_hpo = {}\n",
        "    disease_to_name = {}\n",
        "\n",
        "    ontology = pronto.Ontology('./hpo.obo')\n",
        "\n",
        "    with open(hpo_disease_annotations, 'r') as anno_handle:\n",
        "        header = None\n",
        "        for anno_line in anno_handle:\n",
        "\n",
        "            if anno_line.startswith('#'):\n",
        "                continue\n",
        "\n",
        "            if not header:\n",
        "                header = anno_line.strip().split('\\t')\n",
        "                continue\n",
        "\n",
        "            disease_id, disease_name, _, hpo_id = anno_line.split('\\t')[0:4]\n",
        "\n",
        "            if disease_id not in disease_to_hpo:  # create dictionary of disease -> set (HPO terms)\n",
        "                disease_to_hpo[disease_id] = set()\n",
        "                disease_to_name[disease_id] = disease_name\n",
        "\n",
        "            disease_to_hpo[disease_id].add(hpo_id)\n",
        "\n",
        "            # get all parents and add it to the same disease\n",
        "            parents = get_ancestors_up_to_root(ontology, hpo_id)\n",
        "            for parent in parents:\n",
        "                disease_to_hpo[disease_id].add(parent)\n",
        "\n",
        "    # storing it as a json file here\n",
        "    import json\n",
        "    new_d = {}\n",
        "    for k, v in disease_to_hpo.items():\n",
        "        new_d[k] = list(v)\n",
        "    with open('./disease_to_hpo.json', 'w') as fp:\n",
        "        json.dump(new_d, fp)\n",
        "\n",
        "    print(\"Number of diseases with annotations = \" + str(len(disease_to_hpo.keys())))\n",
        "    print(\"Average number terms/disease = \" + str(\n",
        "        sum([len(v) for v in disease_to_hpo.values()]) / len(disease_to_hpo.keys())))\n",
        "\n",
        "    return disease_to_hpo, disease_to_name"
      ],
      "metadata": {
        "id": "c6J5viE6HEnS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_disease_annotations('/content/phenotype.hpoa')"
      ],
      "metadata": {
        "id": "SghyYOfaIciJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/disease_to_hpo.json', 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "AiubBCsHOrpT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for i in data.values():\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izetW6sKPALA",
        "outputId": "e9febf8a-fd8e-4f21-fde5-fa6035def0c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer, Dataset and DataLoader"
      ],
      "metadata": {
        "id": "5CdRCfOmMWSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "'''\n",
        "X - Phenotypes\n",
        "Y - Disease\n",
        "\n",
        "Approach - Sample random phenotypes from X (30 pct)\n",
        "Y - Disease\n",
        "\n",
        "Model - Transformer\n",
        "Sequential Data\n",
        "\n",
        "X - already a list of phenotypes\n",
        "Conver this X to Embeddings\n",
        "1. Add a cls token embedding at the start\n",
        "2. Pad them for the symptom length\n",
        "No positional encoding\n",
        "\n",
        "Model:\n",
        "\n",
        "Transformer\n",
        "1. Masked Attention Needs to be done and avoid all pad tokens\n",
        "2. Multi head Attention\n",
        "\n",
        "Loss Function: Cross Entropy Loss\n",
        "Optimizer: AdamW\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "Model Initialization: Kaiming Init - Or, lets experiment - With random variances, the key that final activation should have\n",
        "a standard normal distribution\n",
        "'''"
      ],
      "metadata": {
        "id": "0Pnsq53ZPkqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "c55c1ed1-7584-4841-a083-21674a9a8805"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX - Phenotypes\\nY - Disease\\n\\nApproach - Sample random phenotypes from X (30 pct)\\nY - Disease\\n\\nModel - Transformer\\nSequential Data\\n\\nX - already a list of phenotypes\\nConver this X to Embeddings\\n1. Add a cls token embedding at the start\\n2. Pad them for the symptom length\\nNo positional encoding\\n\\nModel:\\n\\nTransformer\\n1. Masked Attention Needs to be done and avoid all pad tokens\\n2. Multi head Attention\\n\\nLoss Function: Cross Entropy Loss\\nOptimizer: AdamW\\n\\n\\n---- \\n\\nModel Initialization: Kaiming Init - Or, lets experiment - With random variances, the key that final activation should have \\na standard normal distribution\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from einops import rearrange\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "b_FnX5F_BTzq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer():\n",
        "    def __init__(self, pheno_list, tokenizer_path = None, max_len = 256, save_path = None):\n",
        "\n",
        "        if tokenizer_path:\n",
        "            try:\n",
        "                with open(tokenizer_path, 'rb') as f:\n",
        "                    self = pickle.load(f)\n",
        "                    return\n",
        "            except:\n",
        "                print('TOKENIZER NOT FOUND, INITIALIZING NEW ONE')\n",
        "\n",
        "        self.key_value = {\n",
        "            'CLS_KEY': 0,\n",
        "            'PAD_KEY': 1,\n",
        "            'UNK': 2\n",
        "        }\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.phenotype_list = pheno_list\n",
        "        for idx, pheno in enumerate(pheno_list):\n",
        "            self.key_value[pheno] = idx + 3\n",
        "\n",
        "        self.value_key = {v: k for k, v in self.key_value.items()}\n",
        "        if save_path:\n",
        "            self.save_tokenizer(save_path)\n",
        "\n",
        "    def get_key(self, pheno):\n",
        "        try:\n",
        "            return self.key_value[pheno]\n",
        "        except:\n",
        "            return self.key_value['UNK']\n",
        "\n",
        "    def save_tokenizer(self, tokenizer_path):\n",
        "        print(f'SAVING TOKENIZER AT: {tokenizer_path}')\n",
        "        with open(tokenizer_path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    def _tokenize(self, pheno_list):\n",
        "        return [self.key_value[pheno] if pheno in self.key_value else self.key_value['UNK'] for pheno in pheno_list]\n",
        "\n",
        "    def pad(self, pheno_list):\n",
        "        pheno_list = ['CLS_KEY'] + pheno_list\n",
        "        delta = max(0, (self.max_len - len(pheno_list)))\n",
        "        if len(pheno_list) < self.max_len:\n",
        "            pheno_list += ['PAD_KEY'] * (self.max_len - len(pheno_list))\n",
        "        else:\n",
        "            pheno_list = pheno_list[:self.max_len]\n",
        "\n",
        "        assert len(pheno_list) == self.max_len\n",
        "        return pheno_list, delta\n",
        "\n",
        "    def tokenize(self, pheno_list):\n",
        "        # 2 things\n",
        "        # 1. Tokenized Pheno List\n",
        "        # 2. Pad Mask\n",
        "        padded_pheno_list, n_padded = self.pad(pheno_list)\n",
        "        tokenized_pheno_list = torch.tensor(self._tokenize(padded_pheno_list)).to(torch.long)\n",
        "        pad_mask = torch.tensor([1] * (self.max_len - n_padded) + [0] * n_padded).to(torch.long)\n",
        "\n",
        "        # Verification\n",
        "        assert len(tokenized_pheno_list) == self.max_len\n",
        "        assert len(pad_mask) == self.max_len\n",
        "\n",
        "        return tokenized_pheno_list, pad_mask\n",
        "\n",
        "    def reverse_tokenize(self, tokenized_pheno_list):\n",
        "        return [self.value_key[token] for token in tokenized_pheno_list]"
      ],
      "metadata": {
        "id": "wt9o2mSPC6-4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/disease_to_hpo.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "values = []\n",
        "for i in data.values():\n",
        "    values.extend(i)\n",
        "pheno_list = list(set(values))"
      ],
      "metadata": {
        "id": "YT2mgvqxFN8f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(pheno_list, max_len = 256, save_path = '/content/tokenizer.pkl')\n",
        "# tokenizer = Tokenizer(pheno_list, tokenizer_path = '/content/tokenizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deWMNAbuMi8N",
        "outputId": "4e0b220f-2104-4547-d1c7-22c948458362"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVING TOKENIZER AT: /content/tokenizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(data.values())[0]\n",
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeR_86w9Ngb7",
        "outputId": "2f402a5e-36d4-4754-97c7-484db8b8ad37"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class DS(Dataset):\n",
        "    def __init__(self, data_dict, tokenizer, save_path = None):\n",
        "        self.data = data_dict\n",
        "\n",
        "        self.X = list(data_dict.values())\n",
        "        self.Y = list(data_dict.keys())\n",
        "        self.Y_values = {y: i for i, y in enumerate(self.Y)}\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if save_path:\n",
        "            self.save_dataset(save_path)\n",
        "\n",
        "    def save_dataset(self, save_path):\n",
        "        print(f'SAVING DATASET AT: {save_path}')\n",
        "        with open(save_path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        y = self.Y[idx]\n",
        "\n",
        "        if len(x) > self.tokenizer.max_len:\n",
        "            # sample tokenizer.max_len number of items out of this list randomly\n",
        "            sampled_indices = random.sample(range(len(x)), self.tokenizer.max_len)\n",
        "            x = [x[i] for i in sampled_indices]\n",
        "\n",
        "        elif len(x) < self.tokenizer.max_len:\n",
        "            # sample somewhere between 30% to 70% of x randomly\n",
        "            sample_percentage = random.uniform(0.2, 0.99)\n",
        "            sample_size = max(1, int(len(x) * sample_percentage))\n",
        "            sampled_indices = random.sample(range(len(x)), sample_size)\n",
        "            x = [x[i] for i in sampled_indices]\n",
        "\n",
        "        tokens, mask = self.tokenizer.tokenize(x)\n",
        "        return (tokens, mask), self.Y_values[y]"
      ],
      "metadata": {
        "id": "cTUqDhEfOelJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DS(data, tokenizer)\n",
        "# with open('/content/dataset.pkl', 'rb') as f:\n",
        "#     dataset = pickle.load(f)\n",
        "dataloader = DataLoader(dataset, batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "7k7zRDhfQzCh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YAY Dataset is working and verified\n",
        "(tokens, mask), disease = dataset[0]"
      ],
      "metadata": {
        "id": "I-5KSXKNTSYo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the Dataset\n",
        "with open('/content/dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset, f)"
      ],
      "metadata": {
        "id": "1m3yghk_uatA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter_data = iter(dataloader)\n",
        "x, y = next(iter_data)"
      ],
      "metadata": {
        "id": "MyGrCPxlT7w_"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].shape, x[1].shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMpWh9dlVQnj",
        "outputId": "7ee45167-ae8b-46d6-cac5-4b4b919a2db2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 256]), torch.Size([64, 256]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.key_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6ruvL7_k1W5",
        "outputId": "46e87163-e5b8-4751-e8b8-4de243eb25d8"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12508"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets Write the Transformer MANNNNN!!!!!!"
      ],
      "metadata": {
        "id": "OywRfxxeWNT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(module):\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "        # Initialize linear and embedding weights with Kaiming initialization\n",
        "        nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
        "        if hasattr(module, 'bias') and module.bias is not None:\n",
        "            nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, (nn.LayerNorm, nn.GroupNorm)):\n",
        "        # Initialize normalization layer parameters\n",
        "        if module.weight is not None:\n",
        "            nn.init.ones_(module.weight)\n",
        "        if module.bias is not None:\n",
        "            nn.init.zeros_(module.bias)\n",
        "\n",
        "class MultiHeadAttention(nn.Module): # Verified\n",
        "\n",
        "    def __init__(self, d_model, nhead):\n",
        "\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "\n",
        "        self.kqv = nn.Linear(d_model, 3*d_model)\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "\n",
        "        # x -> (b, s, e) -> (b s, h, e/h)\n",
        "        kqv = self.kqv(x) # (b, s, 3*d_model)\n",
        "        k, q, v = torch.chunk(kqv, 3, dim = -1) # (3, b, s, d_model)\n",
        "\n",
        "        k = rearrange(k, 'b s (h e) -> b h s e', h = self.nhead)\n",
        "        q = rearrange(q, 'b s (h e) -> b h s e', h = self.nhead)\n",
        "        v = rearrange(v, 'b s (h e) -> b h s e', h = self.nhead)\n",
        "\n",
        "        # Attention claculation - # TODO: make is_casual true in case of finetuning - Very important\n",
        "        y = F.scaled_dot_product_attention(q, k, v, attn_mask = attention_mask[:, None, None, :], is_causal = False) # flash attention\n",
        "        y = rearrange(y, 'b h s e -> b s (h e)', h = self.nhead)\n",
        "\n",
        "        return self.proj(y)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(d_model, 4 * d_model),\n",
        "            nn.GELU(approximate = 'tanh'),\n",
        "            nn.Linear(4 * d_model, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead):\n",
        "        # Self Attn\n",
        "        # MLP\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, nhead)\n",
        "        self.mlp = MLP(d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn = self.self_attn(x, mask)\n",
        "        x = self.norm1(x + attn)\n",
        "        mlp_out = self.mlp(x)\n",
        "        x = self.norm2(x + mlp_out)\n",
        "        return x\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim = 512, n_classes = 12687, n_layers = 8, n_heads = 16):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.transformers = nn.ModuleList([EncoderLayer(d_model = emb_dim, nhead = n_heads) for _ in range(n_layers)])\n",
        "        self.classifier = nn.Linear(emb_dim, n_classes)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # breakpoint()\n",
        "        x = self.embedding(x) # (b, s, e)\n",
        "        x = self.norm(x) # (b, s, e)\n",
        "        mask = mask.bool()\n",
        "        for transformer in self.transformers:\n",
        "            x = transformer(x, mask)\n",
        "\n",
        "        x = x[:, 0, :].squeeze() # (b, s, e) -> (b, e)\n",
        "        x = self.classifier(x) # (b, e) -> (b, num_classes)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rhl98a07VU_c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(len(tokenizer.key_value), n_layers = 8)\n",
        "model = model.apply(init_weights)"
      ],
      "metadata": {
        "id": "QXFtlOaZXR20"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens, mask = x[0], x[1]\n",
        "logits = model(tokens, mask)"
      ],
      "metadata": {
        "id": "7nPnfAxmmUB5"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape, y.dtype, logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRXAe3YprcdY",
        "outputId": "96d4566d-4832-41b1-c53a-661d44d18673"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64]), torch.int64, torch.Size([64, 12687]))"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = AdamW(model.parameters(), lr = max_lr, weight_decay = 1e-02)\n",
        "\n",
        "for i in range(10):\n",
        "    opt.zero_grad()\n",
        "    logits = model(tokens, mask)\n",
        "    loss = loss_fn(logits, y)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMV39Zbtrpxa",
        "outputId": "53912bb7-b06d-4b60-ea2e-e5b4fba08401"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.484833717346191\n",
            "8.209488868713379\n",
            "6.239413738250732\n",
            "4.530508518218994\n",
            "3.043102264404297\n",
            "1.8216582536697388\n",
            "0.9548807144165039\n",
            "0.435703307390213\n",
            "0.1810034066438675\n",
            "0.07764700055122375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtZUL7knrrYJ",
        "outputId": "d43e0d7d-75c0-40bf-ee36-b23d7c83efa4"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.7035, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z99_114Bv7FZ",
        "outputId": "9bf26c1b-d8a3-41f0-ee75-eed30d5fc381"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the initial model"
      ],
      "metadata": {
        "id": "i_KD33-GwJ9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "del model\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "5qA2klLlwTRl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size = 192, shuffle = True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Net(len(tokenizer.key_value), n_layers = 6)\n",
        "model = model.apply(init_weights)\n",
        "model = model.to(device)\n",
        "\n",
        "max_lr = 5e-04\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "opt = AdamW(model.parameters(), lr = max_lr, weight_decay = 1e-02)\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt,\n",
        "                                                   max_lr,\n",
        "                                                   epochs=epochs,\n",
        "                                                   steps_per_epoch=len(dataloader),\n",
        "                                                   pct_start=0.1,\n",
        "                                                   anneal_strategy='cos',\n",
        "                                                   cycle_momentum=True,\n",
        "                                                   base_momentum=0.85,\n",
        "                                                   max_momentum=0.95,\n",
        "                                                   div_factor=100.0,\n",
        "                                                   final_div_factor=1000,\n",
        "                                                   last_epoch=-1)\n",
        "\n",
        "# variances = np.linspace(0.05, 0.15, epochs)\n",
        "train_losses = []\n",
        "for epoch in range(epochs):\n",
        "    train_iter = iter(dataloader)\n",
        "    for it, (x, y) in enumerate(train_iter):\n",
        "\n",
        "        tokens, mask = x[0].to(device), x[1].to(device)\n",
        "        y = y.to(torch.long).to(device)\n",
        "\n",
        "        logits = model(tokens, mask)\n",
        "        loss = loss_fn(logits, y)\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Train Loss: {np.mean(train_losses[-len(dataloader):]):.4f}\")\n",
        "    if epoch % 5 == 0: # do checkpointing\n",
        "        # PLS FINISH THE CODE\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': opt.state_dict(),\n",
        "            'scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'loss': np.mean(train_losses[-len(dataloader):])\n",
        "        }\n",
        "        torch.save(checkpoint, f'/content/drive/MyDrive/hrd_hack/model_checkpoint_epoch_{epoch}.pt')\n",
        "        print(f\"Checkpoint saved at epoch {epoch}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4HVgSEumWYu",
        "outputId": "4d10aca4-bca0-4cbf-8f80-b0351f2b8294"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 10.4448\n",
            "Checkpoint saved at epoch 0\n",
            "Epoch: 1 | Train Loss: 10.2200\n",
            "Epoch: 2 | Train Loss: 10.0366\n",
            "Epoch: 3 | Train Loss: 9.9041\n",
            "Epoch: 4 | Train Loss: 9.8188\n",
            "Epoch: 5 | Train Loss: 9.7992\n",
            "Checkpoint saved at epoch 5\n",
            "Epoch: 6 | Train Loss: 9.7700\n",
            "Epoch: 7 | Train Loss: 9.6116\n",
            "Epoch: 8 | Train Loss: 9.2823\n",
            "Epoch: 9 | Train Loss: 8.8428\n",
            "Epoch: 10 | Train Loss: 8.3100\n",
            "Checkpoint saved at epoch 10\n",
            "Epoch: 11 | Train Loss: 7.7741\n",
            "Epoch: 12 | Train Loss: 7.2526\n",
            "Epoch: 13 | Train Loss: 6.8192\n",
            "Epoch: 14 | Train Loss: 6.3889\n",
            "Epoch: 15 | Train Loss: 6.0309\n",
            "Checkpoint saved at epoch 15\n",
            "Epoch: 16 | Train Loss: 5.6587\n",
            "Epoch: 17 | Train Loss: 5.3335\n",
            "Epoch: 18 | Train Loss: 5.0220\n",
            "Epoch: 19 | Train Loss: 4.7063\n",
            "Epoch: 20 | Train Loss: 4.4632\n",
            "Checkpoint saved at epoch 20\n",
            "Epoch: 21 | Train Loss: 4.1345\n",
            "Epoch: 22 | Train Loss: 3.8826\n",
            "Epoch: 23 | Train Loss: 3.6099\n",
            "Epoch: 24 | Train Loss: 3.3966\n",
            "Epoch: 25 | Train Loss: 3.1438\n",
            "Checkpoint saved at epoch 25\n",
            "Epoch: 26 | Train Loss: 2.9137\n",
            "Epoch: 27 | Train Loss: 2.7332\n",
            "Epoch: 28 | Train Loss: 2.5555\n",
            "Epoch: 29 | Train Loss: 2.3658\n",
            "Epoch: 30 | Train Loss: 2.2922\n",
            "Checkpoint saved at epoch 30\n",
            "Epoch: 31 | Train Loss: 2.0537\n",
            "Epoch: 32 | Train Loss: 1.9238\n",
            "Epoch: 33 | Train Loss: 1.7541\n",
            "Epoch: 34 | Train Loss: 1.6957\n",
            "Epoch: 35 | Train Loss: 1.6450\n",
            "Checkpoint saved at epoch 35\n",
            "Epoch: 36 | Train Loss: 1.5376\n",
            "Epoch: 37 | Train Loss: 1.5124\n",
            "Epoch: 38 | Train Loss: 1.4016\n",
            "Epoch: 39 | Train Loss: 1.3133\n",
            "Epoch: 40 | Train Loss: 1.2822\n",
            "Checkpoint saved at epoch 40\n",
            "Epoch: 41 | Train Loss: 1.2355\n",
            "Epoch: 42 | Train Loss: 1.1831\n",
            "Epoch: 43 | Train Loss: 1.1383\n",
            "Epoch: 44 | Train Loss: 1.0628\n",
            "Epoch: 45 | Train Loss: 1.0330\n",
            "Checkpoint saved at epoch 45\n",
            "Epoch: 46 | Train Loss: 1.0335\n",
            "Epoch: 47 | Train Loss: 1.0328\n",
            "Epoch: 48 | Train Loss: 0.9533\n",
            "Epoch: 49 | Train Loss: 0.9157\n",
            "Epoch: 50 | Train Loss: 0.9038\n",
            "Checkpoint saved at epoch 50\n",
            "Epoch: 51 | Train Loss: 0.8384\n",
            "Epoch: 52 | Train Loss: 0.8440\n",
            "Epoch: 53 | Train Loss: 0.8279\n",
            "Epoch: 54 | Train Loss: 0.7758\n",
            "Epoch: 55 | Train Loss: 0.7840\n",
            "Checkpoint saved at epoch 55\n",
            "Epoch: 56 | Train Loss: 0.7814\n",
            "Epoch: 57 | Train Loss: 0.7425\n",
            "Epoch: 58 | Train Loss: 0.7052\n",
            "Epoch: 59 | Train Loss: 0.7150\n",
            "Epoch: 60 | Train Loss: 0.6839\n",
            "Checkpoint saved at epoch 60\n",
            "Epoch: 61 | Train Loss: 0.6980\n",
            "Epoch: 62 | Train Loss: 0.6757\n",
            "Epoch: 63 | Train Loss: 0.6401\n",
            "Epoch: 64 | Train Loss: 0.6202\n",
            "Epoch: 65 | Train Loss: 0.6228\n",
            "Checkpoint saved at epoch 65\n",
            "Epoch: 66 | Train Loss: 0.5843\n",
            "Epoch: 67 | Train Loss: 0.5750\n",
            "Epoch: 68 | Train Loss: 0.5554\n",
            "Epoch: 69 | Train Loss: 0.5470\n",
            "Epoch: 70 | Train Loss: 0.5675\n",
            "Checkpoint saved at epoch 70\n",
            "Epoch: 71 | Train Loss: 0.5518\n",
            "Epoch: 72 | Train Loss: 0.5407\n",
            "Epoch: 73 | Train Loss: 0.5112\n",
            "Epoch: 74 | Train Loss: 0.5262\n",
            "Epoch: 75 | Train Loss: 0.5140\n",
            "Checkpoint saved at epoch 75\n",
            "Epoch: 76 | Train Loss: 0.4942\n",
            "Epoch: 77 | Train Loss: 0.4728\n",
            "Epoch: 78 | Train Loss: 0.4635\n",
            "Epoch: 79 | Train Loss: 0.4712\n",
            "Epoch: 80 | Train Loss: 0.4451\n",
            "Checkpoint saved at epoch 80\n",
            "Epoch: 81 | Train Loss: 0.4505\n",
            "Epoch: 82 | Train Loss: 0.4266\n",
            "Epoch: 83 | Train Loss: 0.4405\n",
            "Epoch: 84 | Train Loss: 0.4438\n",
            "Epoch: 85 | Train Loss: 0.4252\n",
            "Checkpoint saved at epoch 85\n",
            "Epoch: 86 | Train Loss: 0.4334\n",
            "Epoch: 87 | Train Loss: 0.4183\n",
            "Epoch: 88 | Train Loss: 0.4246\n",
            "Epoch: 89 | Train Loss: 0.4134\n",
            "Epoch: 90 | Train Loss: 0.4140\n",
            "Checkpoint saved at epoch 90\n",
            "Epoch: 91 | Train Loss: 0.4106\n",
            "Epoch: 92 | Train Loss: 0.4125\n",
            "Epoch: 93 | Train Loss: 0.3938\n",
            "Epoch: 94 | Train Loss: 0.4088\n",
            "Epoch: 95 | Train Loss: 0.4120\n",
            "Checkpoint saved at epoch 95\n",
            "Epoch: 96 | Train Loss: 0.3976\n",
            "Epoch: 97 | Train Loss: 0.3959\n",
            "Epoch: 98 | Train Loss: 0.3932\n",
            "Epoch: 99 | Train Loss: 0.3892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': opt.state_dict(),\n",
        "            'scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'loss': np.mean(train_losses[-len(dataloader):])\n",
        "        }\n",
        "torch.save(checkpoint, f'/content/drive/MyDrive/hrd_hack/model_checkpoint_epoch_{epoch}.pt')\n",
        "print(f\"Checkpoint saved at epoch {epoch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jEntpFMouHM",
        "outputId": "5beb12ef-c654-4e83-c10c-c20e8120634a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at epoch 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51lCSfylnswb",
        "outputId": "d2d0d6a9-6aa0-40ab-947e-10b8c942885f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([    0,  1288,  8984, 11900,  9595,  8750,  5646,  5271,  9969, 10099,\n",
              "           7065,  8349, 11069,  3479,  3452,  7142,  6165, 11255,  8534,  7776,\n",
              "           6539,  1662,  7641,  7987,  4184, 11609,  2916,  4622,  9258,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1]),\n",
              "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/ds_test.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset, f)"
      ],
      "metadata": {
        "id": "EmjcsHCPmXRs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zva4DEZTn8UC",
        "outputId": "d03679ef-7212-421e-bc2f-7d9e2c3bf731"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/tokenizer_test.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "fZRABg2Yn5To"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/ds_test.pkl', 'rb') as f:\n",
        "    dataset_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "HVmK9opwnwc5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRkvVLVSnzsi",
        "outputId": "67238989-2340-438a-d565-b17f4bfe1429"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([    0,  7776, 11609,  5271,  6539,  8984,  8647, 10099,  2916,  7142,\n",
              "          11255,  5646,  8750,  1662,  9967,  9969,  1288, 11900,  6165,  8349,\n",
              "           7065,  8534,  3452,  7641,  9595,  9258,  7987,  4184, 11069,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1]),\n",
              "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/tokenizer_test.pkl', 'rb') as f:\n",
        "    tokenizer_test = pickle.load(f)\n",
        "tokenizer_test.max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNS3p6kkn1Fo",
        "outputId": "7cffcae9-8ed7-47f0-f908-5c9bad3b65fd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets Create DISEASE Embeddings"
      ],
      "metadata": {
        "id": "VyCKfHFG-UiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1 calculate IC scores for each of the phenotype\n",
        "# for each disease - create a hpo_id_token array and also create a IC score array\n",
        "# Multiply, add and divide by sum of IC Scores\n",
        "# May be Normalize it and visualize"
      ],
      "metadata": {
        "id": "iwfLqgMi-ZuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/tokenizer_test.pkl', 'rb') as f:\n",
        "    tokenizer_test = pickle.load(f)\n",
        "tokenizer_test.max_len\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh3VuHcvCOP5",
        "outputId": "d1274054-e420-44ff-9cba-027d0bc6f94a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/ds_test.pkl', 'rb') as f:\n",
        "    dataset_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "rgcXX8JfCOWh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the frequencies\n",
        "# calculate the -log of frequencies"
      ],
      "metadata": {
        "id": "zmManInnCOf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/disease_to_hpo_with_parents.json', 'r') as f:\n",
        "    disease_to_hpo = json.load(f)"
      ],
      "metadata": {
        "id": "N-i_4sHWCOjj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Spi6i_NZHN",
        "outputId": "63f7b225-3033-4f6f-ebf5-edf954bbc7b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function math.log>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_diseases = len(disease_to_hpo)\n",
        "symptoms = []\n",
        "for k, v in disease_to_hpo.items():\n",
        "    symptoms += v\n",
        "\n",
        "from collections import Counter\n",
        "num_repetetions = Counter(symptoms)\n",
        "\n",
        "ic_scores = {}\n",
        "for k, v in num_repetetions.items():\n",
        "    ic_scores[k] = -math.log(v / total_diseases)"
      ],
      "metadata": {
        "id": "BaUThJXXMcWm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now token_id to ic socre\n",
        "\n",
        "token_id_to_ic = {}\n",
        "for k, v in tokenizer_test.key_value.items():\n",
        "    if k in ic_scores:\n",
        "        token_id_to_ic[v] = ic_scores[k]\n",
        "    else:\n",
        "        token_id_to_ic[v] = 0.0"
      ],
      "metadata": {
        "id": "9R2ALqhKN0K6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = torch.load('./drive/MyDrive/hrd_hack/model_checkpoint_epoch_99.pt', map_location = 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0BDmg4aPumq",
        "outputId": "893ad13e-03ee-4386-acde-facc8469db11"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-2686d48a641f>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_dict = torch.load('./drive/MyDrive/hrd_hack/model_checkpoint_epoch_99.pt', map_location = 'cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict.keys()\n",
        "tokenizer = tokenizer_test\n",
        "model = Net(len(tokenizer.key_value), n_layers = 6)\n",
        "# model  = model.apply(init_weights)\n",
        "model.load_state_dict(model_dict['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_zUT83FP3ox",
        "outputId": "0cfc1f1f-40f7-4eb0-d1bc-2f4c37c9d544"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs = model.embedding.weight.detach().cpu()\n",
        "disease = 'OMIM:619340'\n",
        "hpo = disease_to_hpo[disease]\n",
        "hpo_tokens = torch.tensor(tokenizer._tokenize(hpo)).to(torch.long)\n",
        "ic_scores = torch.tensor([token_id_to_ic[int(token)] for token in hpo_tokens])\n",
        "dis_embs = embs[hpo_tokens]\n",
        "\n",
        "weighted_embs = dis_embs * ic_scores.unsqueeze(1)\n",
        "final_disease_emb = weighted_embs.sum(0)\n"
      ],
      "metadata": {
        "id": "KTugJ7TYTK-4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpo_tokens.shape, ic_scores.shape, embs[hpo_tokens].shape, weighted_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM9PhJW0Tx2a",
        "outputId": "7efffc32-cda1-4194-d8cf-d0c265f5ae6c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60]),\n",
              " torch.Size([60]),\n",
              " torch.Size([60, 512]),\n",
              " torch.Size([60, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_disease_emb = weighted_embs.sum(0)/ic_scores.sum()\n",
        "final_disease_emb.mean(), final_disease_emb.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2q6sJQfUv6R",
        "outputId": "0a3f46f3-558d-46d7-a6d2-07d88a994bd5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0005), tensor(0.0131))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs.mean(), embs.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QDMmV1tU-_1",
        "outputId": "ae34db59-f760-43c9-9030-f996d7ee1485"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.2793e-05), tensor(0.0668))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "final_disease_embs = []\n",
        "embs = model.embedding.weight.detach().cpu()\n",
        "for disease, did in tqdm(dataset_test.Y_values.items()):\n",
        "    hpo = disease_to_hpo[disease]\n",
        "    hpo_tokens = torch.tensor(tokenizer._tokenize(hpo)).to(torch.long)\n",
        "    ic_scores = torch.tensor([token_id_to_ic[int(token)] for token in hpo_tokens])\n",
        "    dis_embs = embs[hpo_tokens]\n",
        "\n",
        "    weighted_embs = dis_embs * ic_scores.unsqueeze(1)\n",
        "    final_disease_emb = weighted_embs.sum(0)\n",
        "    final_disease_embs.append(final_disease_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfmLrCfIRih3",
        "outputId": "c6c6f29c-c6e5-48ce-d19b-2b56b66ace87"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12687/12687 [00:07<00:00, 1709.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disease_embs = torch.stack(final_disease_embs)\n",
        "disease_embs = (disease_embs - disease_embs.mean(0))/disease_embs.std(0)"
      ],
      "metadata": {
        "id": "Kx1DAPekXJq3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disease_embs.mean(), disease_embs.std(), disease_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk1rzEOKXX8o",
        "outputId": "38d9bcaa-b289-4a31-acf2-90e245f94b4d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.6867e-11), tensor(1.0000), torch.Size([12687, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(disease_embs, './drive/MyDrive/hrd_hack/disease_embs.pt')"
      ],
      "metadata": {
        "id": "uYIt9ADVX92w"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_distance(emb1, emb2):\n",
        "    assert emb1.shape == emb2.shape\n",
        "    diff_squared = (emb1 - emb2)**2\n",
        "    return torch.sqrt(diff_squared.sum())\n",
        "\n",
        "print(torch.dist(disease_embs[0], disease_embs[1], p = 2))\n",
        "print(l2_distance(disease_embs[0], disease_embs[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx29NDdXYSAm",
        "outputId": "707d908d-2967-44d8-9ec5-fc6bd27a799c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.4131)\n",
            "tensor(18.4131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate inter embedding distances and then plot a histogram\n",
        "distances = []\n",
        "def l2_distance(emb1, emb2):\n",
        "    assert emb1.shape == emb2.shape\n",
        "    diff_squared = (emb1 - emb2)**2\n",
        "    return torch.sqrt(diff_squared.sum())\n",
        "\n",
        "for i in tqdm(range(disease_embs.shape[0])):\n",
        "    for j in range(i+1, disease_embs.shape[0]):\n",
        "        distances.append(torch.dist(disease_embs[i], disease_embs[j], p = 2).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmpHfVsVYGwn",
        "outputId": "00c57d2b-69df-4238-c3dc-ed6ebb4b96a6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12687/12687 [22:45<00:00,  9.29it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-1FUTYwgtxP",
        "outputId": "844ff69e-0200-4e47-e13d-4bb9b42f2447"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80473641"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.mean(distances), np.std(distances), min(distances), max(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06gueh-vYG9Q",
        "outputId": "15a2162a-5370-4eff-edbf-8433b16efd25"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.073520401521733"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('./drive/MyDrive/hrd_hack/distances.pkl', 'wb') as f:\n",
        "    pickle.dump(distances, f)"
      ],
      "metadata": {
        "id": "Gt-5v_kmhH0s"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/hrd_hack/distances.pkl', 'rb') as f:\n",
        "    distances = pickle.load(f)"
      ],
      "metadata": {
        "id": "9Eje7S8qhocW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances = np.array(distances)"
      ],
      "metadata": {
        "id": "cdownwimiX7p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import hist\n",
        "hist(distances, bins = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xiexk-f2g1FX",
        "outputId": "e5330a95-f82c-4d9c-92f6-6117737217f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.792000e+03, 7.246000e+03, 2.016900e+04, 5.180600e+04,\n",
              "        1.209060e+05, 2.378580e+05, 3.817160e+05, 5.778580e+05,\n",
              "        8.187070e+05, 1.105850e+06, 1.424407e+06, 1.791895e+06,\n",
              "        2.149236e+06, 2.483662e+06, 2.861260e+06, 3.205447e+06,\n",
              "        3.490353e+06, 3.721430e+06, 3.899931e+06, 3.994004e+06,\n",
              "        3.998273e+06, 3.971849e+06, 3.875165e+06, 3.745792e+06,\n",
              "        3.540908e+06, 3.325943e+06, 3.090640e+06, 2.816880e+06,\n",
              "        2.580256e+06, 2.349676e+06, 2.111918e+06, 1.891955e+06,\n",
              "        1.669309e+06, 1.456938e+06, 1.270733e+06, 1.089673e+06,\n",
              "        9.306780e+05, 7.850970e+05, 6.473860e+05, 5.484830e+05,\n",
              "        4.672380e+05, 3.917680e+05, 3.178940e+05, 2.508240e+05,\n",
              "        2.017340e+05, 1.684290e+05, 1.327610e+05, 1.022770e+05,\n",
              "        8.364100e+04, 6.756500e+04, 5.465000e+04, 4.295800e+04,\n",
              "        3.340300e+04, 2.766200e+04, 2.166100e+04, 1.533900e+04,\n",
              "        1.097700e+04, 7.803000e+03, 5.377000e+03, 3.882000e+03,\n",
              "        2.768000e+03, 1.885000e+03, 1.363000e+03, 9.450000e+02,\n",
              "        7.060000e+02, 4.700000e+02, 3.150000e+02, 2.390000e+02,\n",
              "        1.930000e+02, 1.810000e+02, 1.290000e+02, 1.060000e+02,\n",
              "        1.560000e+02, 2.220000e+02, 2.870000e+02, 4.860000e+02,\n",
              "        7.430000e+02, 1.447000e+03, 2.316000e+03, 1.816000e+03,\n",
              "        1.411000e+03, 1.086000e+03, 7.750000e+02, 5.670000e+02,\n",
              "        3.770000e+02, 2.290000e+02, 1.880000e+02, 1.240000e+02,\n",
              "        6.500000e+01, 4.200000e+01, 3.000000e+01, 1.400000e+01,\n",
              "        1.300000e+01, 5.000000e+00, 6.000000e+00, 1.000000e+00,\n",
              "        1.000000e+00, 4.000000e+00, 0.000000e+00, 2.000000e+00]),\n",
              " array([  0.        ,   1.32224747,   2.64449493,   3.9667424 ,\n",
              "          5.28898987,   6.61123734,   7.9334848 ,   9.25573227,\n",
              "         10.57797974,  11.9002272 ,  13.22247467,  14.54472214,\n",
              "         15.8669696 ,  17.18921707,  18.51146454,  19.83371201,\n",
              "         21.15595947,  22.47820694,  23.80045441,  25.12270187,\n",
              "         26.44494934,  27.76719681,  29.08944427,  30.41169174,\n",
              "         31.73393921,  33.05618668,  34.37843414,  35.70068161,\n",
              "         37.02292908,  38.34517654,  39.66742401,  40.98967148,\n",
              "         42.31191895,  43.63416641,  44.95641388,  46.27866135,\n",
              "         47.60090881,  48.92315628,  50.24540375,  51.56765121,\n",
              "         52.88989868,  54.21214615,  55.53439362,  56.85664108,\n",
              "         58.17888855,  59.50113602,  60.82338348,  62.14563095,\n",
              "         63.46787842,  64.79012589,  66.11237335,  67.43462082,\n",
              "         68.75686829,  70.07911575,  71.40136322,  72.72361069,\n",
              "         74.04585815,  75.36810562,  76.69035309,  78.01260056,\n",
              "         79.33484802,  80.65709549,  81.97934296,  83.30159042,\n",
              "         84.62383789,  85.94608536,  87.26833282,  88.59058029,\n",
              "         89.91282776,  91.23507523,  92.55732269,  93.87957016,\n",
              "         95.20181763,  96.52406509,  97.84631256,  99.16856003,\n",
              "        100.4908075 , 101.81305496, 103.13530243, 104.4575499 ,\n",
              "        105.77979736, 107.10204483, 108.4242923 , 109.74653976,\n",
              "        111.06878723, 112.3910347 , 113.71328217, 115.03552963,\n",
              "        116.3577771 , 117.68002457, 119.00227203, 120.3245195 ,\n",
              "        121.64676697, 122.96901443, 124.2912619 , 125.61350937,\n",
              "        126.93575684, 128.2580043 , 129.58025177, 130.90249924,\n",
              "        132.2247467 ]),\n",
              " <BarContainer object of 100 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(distances)"
      ],
      "metadata": {
        "id": "yUObhpcjion7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write a reward function"
      ],
      "metadata": {
        "id": "rVc-JYpR-agK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/disease_to_hpo.json', 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "FlUrOqIhA7NH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens = []\n",
        "for k, v in data.items():\n",
        "    lens.append(len(v))\n",
        "np.mean(lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU5fBEZlA8fM",
        "outputId": "9601fa47-c140-4250-ba45-25aa13295e27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.369196815638055"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(lens, bins = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "ONzB-to8A8Z_",
        "outputId": "05025b2c-022d-4b6f-ff06-ced8c184b59f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.137e+03, 1.042e+03, 9.610e+02, 8.510e+02, 7.310e+02, 6.620e+02,\n",
              "        7.050e+02, 6.160e+02, 5.670e+02, 5.410e+02, 7.030e+02, 4.680e+02,\n",
              "        4.190e+02, 3.800e+02, 3.030e+02, 2.610e+02, 2.530e+02, 2.090e+02,\n",
              "        2.100e+02, 1.940e+02, 2.190e+02, 1.290e+02, 1.270e+02, 1.160e+02,\n",
              "        1.010e+02, 8.600e+01, 5.200e+01, 6.500e+01, 5.700e+01, 5.400e+01,\n",
              "        7.600e+01, 4.800e+01, 3.300e+01, 4.100e+01, 2.300e+01, 2.000e+01,\n",
              "        2.300e+01, 2.100e+01, 2.300e+01, 1.200e+01, 2.000e+01, 9.000e+00,\n",
              "        1.300e+01, 1.500e+01, 8.000e+00, 5.000e+00, 4.000e+00, 6.000e+00,\n",
              "        1.000e+00, 5.000e+00, 1.300e+01, 2.000e+00, 2.000e+00, 5.000e+00,\n",
              "        2.000e+00, 6.000e+00, 4.000e+00, 1.000e+00, 5.000e+00, 1.000e+00,\n",
              "        5.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
              "        2.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
              "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00,\n",
              "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
              " array([  1. ,   3.1,   5.2,   7.3,   9.4,  11.5,  13.6,  15.7,  17.8,\n",
              "         19.9,  22. ,  24.1,  26.2,  28.3,  30.4,  32.5,  34.6,  36.7,\n",
              "         38.8,  40.9,  43. ,  45.1,  47.2,  49.3,  51.4,  53.5,  55.6,\n",
              "         57.7,  59.8,  61.9,  64. ,  66.1,  68.2,  70.3,  72.4,  74.5,\n",
              "         76.6,  78.7,  80.8,  82.9,  85. ,  87.1,  89.2,  91.3,  93.4,\n",
              "         95.5,  97.6,  99.7, 101.8, 103.9, 106. , 108.1, 110.2, 112.3,\n",
              "        114.4, 116.5, 118.6, 120.7, 122.8, 124.9, 127. , 129.1, 131.2,\n",
              "        133.3, 135.4, 137.5, 139.6, 141.7, 143.8, 145.9, 148. , 150.1,\n",
              "        152.2, 154.3, 156.4, 158.5, 160.6, 162.7, 164.8, 166.9, 169. ,\n",
              "        171.1, 173.2, 175.3, 177.4, 179.5, 181.6, 183.7, 185.8, 187.9,\n",
              "        190. , 192.1, 194.2, 196.3, 198.4, 200.5, 202.6, 204.7, 206.8,\n",
              "        208.9, 211. ]),\n",
              " <BarContainer object of 100 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(lens)//2\n",
        "sorted(lens)[len(lens)//2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDXJ4XmjA8W9",
        "outputId": "1a000fbb-9ef6-4b0d-cf1c-d5c983201c10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RewardFn():\n",
        "    '''\n",
        "     -alpha(t) * l2_distance\n",
        "\n",
        "    where alpha(t) = α_base + α_scale × (t / t_max)\n",
        "    '''\n",
        "    def __init__(self, max_steps = 22, threshold = 0.5):\n",
        "        self.max_steps = max_steps\n",
        "        self.alpha_base = 0.01\n",
        "        self.alpha_scale = 1.\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "    def calculate_reward(emb_hat, emb, t):\n",
        "        distance = torch.dist(emb_hat, emb, p = 2)\n",
        "\n",
        "        done = distance < self.threshold\n",
        "        alpha = self.alpha_base + self.alpha_scale * (t / self.max_steps)\n",
        "        reward = -alpha * distance\n",
        "        return reward, done"
      ],
      "metadata": {
        "id": "Pa7pm2aRDRKr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 22\n",
        "alpha_base = 0.01\n",
        "alpha_scale = 1.\n",
        "\n",
        "phs = []\n",
        "for t in range(max_steps):\n",
        "    alpha = alpha_base + alpha_scale * (t / max_steps)\n",
        "    phs.append(alpha)\n",
        "\n",
        "plt.plot(phs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "4q-_0s9iDRIA",
        "outputId": "cfe5915a-74cd-4709-c850-8292bd230544"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd5a7c92b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a POC on 10 to 20 Diseases"
      ],
      "metadata": {
        "id": "-O1TGZwd-q-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from einops import rearrange\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "SMclvOaCvecK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets first create a dataset\n",
        "# Actor Network and Critic Network - Symptom and Disease\n",
        "\n",
        "class POCDS(Dataset):\n",
        "    def __init__(self, data_dict, tokenizer, Y_values, Y_embeddings):\n",
        "        self.data = data_dict\n",
        "\n",
        "        self.X = list(data_dict.values())\n",
        "        self.Y = list(data_dict.keys())\n",
        "        self.Y_values = Y_values\n",
        "        self.Y_embeddings = Y_embeddings\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = self.X[idx]\n",
        "        y = self.Y[idx]\n",
        "\n",
        "        random.shuffle(x)\n",
        "\n",
        "        if len(x) >= self.tokenizer.max_len - 1:\n",
        "            x = x[:self.tokenizer.max_len - 1]\n",
        "\n",
        "        y_val = self.Y_values[y]\n",
        "        y_emb = self.Y_embeddings[y_val]\n",
        "\n",
        "        tokens, mask = self.tokenizer.tokenize(x)\n",
        "        return (tokens, mask), y_emb"
      ],
      "metadata": {
        "id": "kQzRRtbyed19"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hrd_hack/ds_test.pkl', 'rb') as f:\n",
        "    original_ds = pickle.load(f)\n",
        "\n",
        "disease_embs = torch.load('/content/drive/MyDrive/hrd_hack/disease_embs.pt')\n",
        "disease_embs = disease_embs.detach().cpu()\n",
        "\n",
        "with open('/content/drive/MyDrive/hrd_hack/disease_to_hpo_with_parents.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "new_data = {}\n",
        "keys = list(data.keys())\n",
        "for i in range(100):\n",
        "    new_data[keys[i]] = data[keys[i]]\n",
        "\n",
        "tokenizer = original_ds.tokenizer\n",
        "dataset = POCDS(new_data, tokenizer, original_ds.Y_values, disease_embs)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size = 100, shuffle = True)\n",
        "x, y = next(iter(dataloader))\n",
        "\n",
        "x[0].shape, x[1].shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqSnjGk7xJZH",
        "outputId": "beb44482-c7cd-4f06-e9e5-f080952fb206"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-32139f6986e8>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  disease_embs = torch.load('/content/drive/MyDrive/hrd_hack/disease_embs.pt')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 256]), torch.Size([100, 256]), torch.Size([100, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class POCActor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim = 512, n_classes = 12687, n_layers = 8, n_heads = 16):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.transformers = nn.ModuleList([EncoderLayer(d_model = emb_dim, nhead = n_heads) for _ in range(n_layers)])\n",
        "\n",
        "        self.final_norm = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        self.emb_transform_mean = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 1024),\n",
        "            nn.GELU(approximate = 'tanh'),\n",
        "            nn.Linear(1024, 512)\n",
        "        )\n",
        "        self.emb_transform_log_std = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 1024),\n",
        "            nn.GELU(approximate = 'tanh'),\n",
        "            nn.Linear(1024, 512)\n",
        "        )\n",
        "\n",
        "    def load_backbone(self, path = './drive/MyDrive/hrd_hack/model_checkpoint_epoch_99.pt'):\n",
        "        checkpoint = torch.load(path, map_location = 'cpu')['model_state_dict']\n",
        "        self_state_dict = self.state_dict()\n",
        "        for k, v in checkpoint.items():\n",
        "            if k in self_state_dict:\n",
        "                if v.shape == self_state_dict[k].shape:\n",
        "                    self_state_dict[k].copy_(v)\n",
        "\n",
        "    def adjust_log_std(self, log_std):\n",
        "        log_std_min, log_std_max = (-5, 2)  # From SpinUp / Denis Yarats\n",
        "        return log_std_min + 0.5 * (log_std_max - log_std_min) * (log_std + 1)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.embedding(x) # (b, s, e)\n",
        "        x = self.norm(x) # (b, s, e)\n",
        "        mask = mask.bool()\n",
        "        for transformer in self.transformers:\n",
        "            x = transformer(x, mask)\n",
        "\n",
        "        x = x[:, 0, :].squeeze() # (b, s, e) -> (b, e)\n",
        "\n",
        "        x = self.final_norm(x).squeeze() # (b, e)\n",
        "\n",
        "        mean = self.emb_transform_mean(x) # (b, e) -> (b, e)\n",
        "\n",
        "        log_std = self.emb_transform_log_std(x) # (b, e) -> (b, e)\n",
        "        log_std = torch.tanh(log_std)\n",
        "        return mean, self.adjust_log_std(log_std)\n",
        "\n",
        "    def get_action(self, x, mask):\n",
        "        mean, log_std = self.forward(x, mask)\n",
        "        std = torch.exp(log_std)\n",
        "        normal = torch.distributions.Normal(mean, std)\n",
        "        x_t = normal.rsample()\n",
        "        log_prob = normal.log_prob(x_t)\n",
        "        return x_t, log_prob\n",
        "\n",
        "class POCCritic(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim = 512, n_classes = 12687, n_layers = 8, n_heads = 16):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.disease_transform = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 1024),\n",
        "            nn.GELU(approximate = 'tanh'),\n",
        "            nn.Linear(1024, 512)\n",
        "        )\n",
        "\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.transformers = nn.ModuleList([EncoderLayer(d_model = emb_dim, nhead = n_heads) for _ in range(n_layers)])\n",
        "        self.final_norm = nn.LayerNorm(emb_dim)\n",
        "        self.q_value = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 1024),\n",
        "            nn.GELU(approximate = 'tanh'),\n",
        "            nn.Linear(1024, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask, d_emb):\n",
        "        # breakpoint()\n",
        "\n",
        "        x = self.embedding(x) # (b, s, e)\n",
        "\n",
        "        d_emb = self.disease_transform(d_emb) # (b, e)\n",
        "        d_emb = d_emb.unsqueeze(1) # (b, s + 1, e)\n",
        "        d_emb_mask = torch.ones(x.shape[0], 1)\n",
        "\n",
        "        mask = torch.cat([mask, d_emb_mask], dim = -1)# (b, s+1, 1)\n",
        "        x = torch.cat([x, d_emb], dim = 1)\n",
        "\n",
        "        x = self.norm(x) # (b, s+1, e)\n",
        "        mask = mask.bool()\n",
        "        for transformer in self.transformers:\n",
        "            x = transformer(x, mask)\n",
        "\n",
        "        x = x[:, 0, :].squeeze() # (b, s, e) -> (b, e)\n",
        "        x = self.final_norm(x)\n",
        "        return self.q_value(x)"
      ],
      "metadata": {
        "id": "GHMCW87wygAW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor = POCActor(len(tokenizer.key_value), n_layers = 6)\n",
        "critic = POCCritic(len(tokenizer.key_value), n_layers = 2)\n",
        "actor.load_backbone()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65I5QP-qyf90",
        "outputId": "3d7c2923-4efa-40a1-b5e1-c89ee47e8494"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-99d97d0369fa>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location = 'cpu')['model_state_dict']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "class ReplayMemoryBuffer:\n",
        "\n",
        "    '''\n",
        "    stores T - current time step\n",
        "    State - Current X\n",
        "    All X - Remaining X\n",
        "    '''\n",
        "    def __init__(self, phenos: list[list], embs: torch.Tensor,  tokenizer: Tokenizer, max_t = 50):\n",
        "        import copy\n",
        "\n",
        "        self.X = copy.deepcopy(phenos)\n",
        "        self.Y = embs\n",
        "\n",
        "        self.state_x = None\n",
        "        self.max_t = max_t\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def get_sample(self):\n",
        "\n",
        "        for phenotypes, present_state in zip(self.X, self.state_x):\n",
        "            if len(phenotypes) > 0:\n",
        "                random.shuffle(phenotypes)\n",
        "                present_state.append(phenotypes.pop(0))\n",
        "            else:\n",
        "                present_state.append('PAD_KEY')\n",
        "        breakpoint()\n",
        "        tokenized_state_x = []\n",
        "        tokenized_state_mask = []\n",
        "\n",
        "        for state in self.state_x:\n",
        "            state_tokenized, state_mask = self.tokenizer.tokenize(state)\n",
        "            tokenized_state_x.append(state_tokenized)\n",
        "            tokenized_state_mask.append(state_mask)\n",
        "\n",
        "        tokenized_state_x = torch.stack(tokenized_state_x)\n",
        "        tokenized_state_mask = torch.stack(tokenized_state_mask)\n",
        "        return (self.t, tokenized_state_x, tokenized_state_mask), y\n",
        "\n",
        "    def get_next(self):\n",
        "\n",
        "        if hasattr(self, 't') and self.t > 0:\n",
        "            self.t += 1\n",
        "        else:\n",
        "            self.t = 0\n",
        "            self.state_x = [[] for _ in range(len(self.X))]\n",
        "\n",
        "        eps_done = self.t > self.max_t\n",
        "        (current_t, tokenized_state_x, tokenized_state_mask), y = self.get_sample()\n",
        "        return eps_done, (current_t, tokenized_state_x, tokenized_state_mask), y\n",
        "\n"
      ],
      "metadata": {
        "id": "54Nh5mPHT_bA"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_values = original_ds.Y_values\n",
        "diseases = list(new_data.keys())\n",
        "disease_ids = [y_values[disease] for disease in diseases]\n",
        "poc_disease_embs = disease_embs[disease_ids]"
      ],
      "metadata": {
        "id": "pFx0x11ZDgJ8"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/hrd_hack/disease_to_hpo_with_parents.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "new_data = {}\n",
        "keys = list(data.keys())\n",
        "for i in range(100):\n",
        "    new_data[keys[i]] = data[keys[i]]\n",
        "\n",
        "poc_phenotypes = list(new_data.values())"
      ],
      "metadata": {
        "id": "hFn96buIT_Y_"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = original_ds.tokenizer\n",
        "replay_buffer = ReplayMemoryBuffer(poc_phenotypes, poc_disease_embs, tokenizer)"
      ],
      "metadata": {
        "id": "JYslSYxNE0Lh"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eps_done, (current_t, tokenized_state_x, tokenized_state_mask), y = replay_buffer.get_next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaaM2hW0FQkY",
        "outputId": "7261460f-62f3-41c0-c51f-3d1affabfe82"
      },
      "execution_count": 96,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-93-3741c8c2dcb0>\u001b[0m(29)\u001b[0;36mget_sample\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     27 \u001b[0;31m                \u001b[0mpresent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PAD_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 29 \u001b[0;31m        \u001b[0mtokenized_state_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     30 \u001b[0;31m        \u001b[0mtokenized_state_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     31 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> self.state_X\n",
            "*** AttributeError: 'ReplayMemoryBuffer' object has no attribute 'state_X'\n",
            "ipdb> self.state_x\n",
            "[['HP:0020219'], ['HP:0000707'], ['HP:0002795'], ['HP:0000664'], ['HP:0001995'], ['HP:0005110'], ['HP:0000001'], ['HP:0005607'], ['HP:0001892'], ['HP:0011443'], ['HP:0001714'], ['HP:4000074'], ['HP:0011446'], ['HP:0040070'], ['HP:0012880'], ['HP:0200127'], ['HP:0030084'], ['HP:0025031'], ['HP:0030012'], ['HP:0000366'], ['HP:0000523'], ['HP:0410042'], ['HP:0000001'], ['HP:0001510'], ['HP:0410042'], ['HP:0000007'], ['HP:0004377'], ['HP:0004328'], ['HP:0031797'], ['HP:0031704'], ['HP:0000504'], ['HP:0011675'], ['HP:0000924'], ['HP:0009830'], ['HP:0003674'], ['HP:0002014'], ['HP:0100834'], ['HP:0000805'], ['HP:0002715'], ['HP:0002321'], ['HP:0000609'], ['HP:0004329'], ['HP:0003674'], ['HP:0000505'], ['HP:0034345'], ['HP:0012638'], ['HP:0011463'], ['HP:0033353'], ['HP:0001263'], ['HP:0004372'], ['HP:0000365'], ['HP:0000599'], ['HP:0012823'], ['HP:0000006'], ['HP:0002980'], ['HP:0011458'], ['HP:0000006'], ['HP:0001249'], ['HP:0100022'], ['HP:0000011'], ['HP:0200065'], ['HP:0007642'], ['HP:0045045'], ['HP:0000301'], ['HP:0000546'], ['HP:0010978'], ['HP:0000551'], ['HP:0000365'], ['HP:0003073'], ['HP:0031654'], ['HP:0005288'], ['HP:0000005'], ['HP:0010461'], ['HP:0034345'], ['HP:0010668'], ['HP:0000079'], ['HP:0000848'], ['HP:0011282'], ['HP:0006695'], ['HP:0000007'], ['HP:0100777'], ['HP:0025066'], ['HP:0011124'], ['HP:0003011'], ['HP:0005943'], ['HP:0032309'], ['HP:0040131'], ['HP:0000032'], ['HP:0000001'], ['HP:0032076'], ['HP:0001574'], ['HP:0000811'], ['HP:0011492'], ['HP:0001098'], ['HP:0000598'], ['HP:0030680'], ['HP:0031816'], ['HP:0000327'], ['HP:0007370'], ['HP:0025031']]\n",
            "ipdb> c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_state_x.shape, tokenized_state_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-n3ZmvCFUGw",
        "outputId": "552550f9-fa5c-47d5-ded5-03bc0d102cfd"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 256]), torch.Size([100, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps_done, (current_t, tokenized_state_x, tokenized_state_mask), y = replay_buffer.get_next()\n",
        "eps_done, (current_t, tokenized_state_x, tokenized_state_mask), y = replay_buffer.get_next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jttBgR8KFbVq",
        "outputId": "1897ffca-ac5e-41f7-ac38-116f77987aa3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-93-3741c8c2dcb0>\u001b[0m(29)\u001b[0;36mget_sample\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     27 \u001b[0;31m                \u001b[0mpresent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PAD_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 29 \u001b[0;31m        \u001b[0mtokenized_state_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     30 \u001b[0;31m        \u001b[0mtokenized_state_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     31 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> self.state_x\n",
            "[['HP:0000001'], ['HP:0001878'], ['HP:0010978'], ['HP:0000309'], ['HP:0001944'], ['HP:0001626'], ['HP:0001939'], ['HP:0002783'], ['HP:0000005'], ['HP:0031826'], ['HP:0003596'], ['HP:5200044'], ['HP:0100538'], ['HP:0030084'], ['HP:0000055'], ['HP:0000001'], ['HP:0009774'], ['HP:0100834'], ['HP:0000202'], ['HP:0006493'], ['HP:0031797'], ['HP:0001438'], ['HP:0000163'], ['HP:0002977'], ['HP:0040134'], ['HP:0000504'], ['HP:0002665'], ['HP:0000005'], ['HP:0000613'], ['HP:0000365'], ['HP:0002423'], ['HP:0012251'], ['HP:0031797'], ['HP:0001939'], ['HP:0002270'], ['HP:0002037'], ['HP:0001909'], ['HP:0012591'], ['HP:0001252'], ['HP:0001751'], ['HP:0100543'], ['HP:0001612'], ['HP:0011025'], ['HP:0000662'], ['HP:0025031'], ['HP:0001321'], ['HP:0011446'], ['HP:0001249'], ['HP:0000929'], ['HP:0100547'], ['HP:0000407'], ['HP:0000153'], ['HP:0000518'], ['HP:0011729'], ['HP:0000001'], ['HP:0002027'], ['HP:0000499'], ['HP:0000811'], ['HP:0010936'], ['HP:0025668'], ['HP:0004323'], ['HP:0000504'], ['HP:0100886'], ['HP:0000508'], ['HP:0012372'], ['HP:0002383'], ['HP:0004329'], ['HP:0033127'], ['HP:0003774'], ['HP:0430000'], ['HP:0001028'], ['HP:0006530'], ['HP:0011844'], ['HP:0001871'], ['HP:0000152'], ['HP:0011842'], ['HP:0040084'], ['HP:0009115'], ['HP:0003577'], ['HP:0000119'], ['HP:0002664'], ['HP:0032180'], ['HP:0040189'], ['HP:0012575'], ['HP:0005280'], ['HP:0012823'], ['HP:0040129'], ['HP:0000954'], ['HP:0000598'], ['HP:0004329'], ['HP:0010765'], ['HP:0000078'], ['HP:0031816'], ['HP:0000001'], ['HP:0003652'], ['HP:0005922'], ['HP:0011843'], ['HP:0000235'], ['HP:0031797'], ['HP:0034345']]\n",
            "ipdb> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_state_x[0], tokenized_state_mask[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH2M-Z1cForT",
        "outputId": "59f39382-f397-40e6-a7b5-880016b09a61"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   0, 4615,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1]),\n",
              " tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    '''\n",
        "    Twin Critic\n",
        "    Actor\n",
        "\n",
        "    Optimization step\n",
        "    '''"
      ],
      "metadata": {
        "id": "ehRG6weQT_Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[], []]\n",
        "for i in x:\n",
        "    i.append(1)\n",
        "for i in x:\n",
        "    i.append(1)\n",
        "\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaS4n17wT_Kc",
        "outputId": "f9080f11-c98f-4ad8-b035-972beda6d76d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1], [1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope it out to the entire dataset"
      ],
      "metadata": {
        "id": "LwZ3qVbR-vQW"
      }
    }
  ]
}